---
title: "[W7] TextAnalytics"
output: 
    html_document:
        theme: default
        highlight: pygments

---

```{r setup, include=FALSE}
knitr::opts_chunk$set()
```

```{r env.setup, echo=TRUE, message=FALSE, warning=FALSE}
# your environment setup
```

R 語言與資料科學導論作業 (W7)
=============================

一般系 b96001001 未命名

## We Are Friends (95%)

### F.R.I.E.N.D.S episode list

「六人行」（[Friends](http://www.imdb.com/title/tt0108778/)）是1994-2004在NBC播出的喜劇影集，描述六名主角Ross, Rachel, Chandler, Monica, Phoebe和Joey在紐約生活的故事。據說，六人行也是很多人學習英文聽力的管道之一。

六人行每集的標題都是以The one with ...開頭。
請下載[檔案](https://raw.githubusercontent.com/RLadsNTU/RLadsLab/master/W7_CorpusAlive/friends_episodes.txt)，包含六人行共236集的標題名稱。並用課堂上所講到的方法（或參考[LetItGo](LetItGo.Rmd)範例），把每個標題當成一個文件，
用tm製作一個六人形影集標題語料庫。


### 一、請將資料讀入VCorpus。 (40%)

請您依序完成以下步驟：

1. 讀入文字檔，若您用`read_file`函數讀文字檔，記得用`strsplit`將每一行都分開來。 (10%)
2. 將所有英文字都變成小寫，你可能會用到的函數是`content_transformer(tolower)`。 (10%)
3. 為了讓一個詞的詞頻能包含其各種詞形變化，我們需要做stemming，您可以參考`stemDocument` (10%)
4. 在這個分析中，我們並不在意高頻詞的出現次數（例如the, of, with）。
所以請用`removeWords`和`stopwords("english")`把英文高頻詞移除。 (10%)

```{r friends.read, echo=TRUE}
# your code goes here.
```

當您準備好VCorpus之後，請用以下這兩行指令把結果呈現出來：

```{r friends.read.res, echo=TRUE, error=TRUE}
# assuming the variable for VCorpus is `vc`
vc
inspect(vc[1:5])
```

### 二、製作文章詞彙矩陣（DocumentTermMatrix） (15%)
```{r friends.tdm, echo=TRUE}
# your code goes here.
```

當您準備好文章詞彙矩陣後之後，請用以下這行指令把結果呈現出來：
```{r friends.dtm.res, echo=TRUE, error=TRUE}
# assuming the variable for DocumentTermMatrix is `dtm`
inspect(dtm)
```

### 三、找出在這份語料中，出現頻率在8次(含)以上的詞，並計算他們的頻率。(40%)

提示：

1. `tm`的文章詞彙矩陣是一個稀疏矩陣（sparse matrix），不適用於`colSums`和`rowSums`。
2. 您可以試試看`findFreqTerm`，在語料庫中尋找常出現的詞彙。 (10%)
3. 當您找到所有的常用詞彙後，把這些詞彙在矩陣中的次數挑選出來（透過indexing），並加總得到其頻率。 (20%)
4. 最後請把這些詞彙按照出現次數，由高到低順序呈現出來。 (10%)

```{r friends.word.freq, echo=TRUE}
# your code goes here.
```

## 進階選答題 (20%)

2017年的國慶日難得的有四天假，同學一定有很多的回憶。但我們沒有同學的假期回憶錄，
所以只好拿10/10當天的總統文告當作練習文本。

請在這個[連結](https://raw.githubusercontent.com/RLadsNTU/RLadsLab/master/W7_CorpusAlive/president_20171010.txt)
下載國慶文告文字檔。並用課堂上的方法，用jiebaR內建辭典，幫這個文字檔斷詞，並製作出詞頻表和文字雲。

提示：

* 請忽略出現次數在5次以下的詞。
* 內建的辭典可能會有很多斷錯的狀況，但這只是練習，請忽略那些錯誤。

### 一、斷詞 (10%)
```{r president.seg, echo=TRUE}
# your code goes here.

```

當您斷詞後，請用以下這行指令把結果呈現出來：
```{r president.seg.res, echo=TRUE, error=TRUE}
# assuming the variable for word segments is `words`
words[1:20]
```

### 二、找出所有出現次數超過5次的詞，並把這些詞和其出現次數列出來 (5%)
```{r president.tetragram, echo=TRUE}
# your code goes here.

```


### 三、畫出文字雲（請去掉最高頻詞） (5%)

文字雲是常常拿來呈現文字頻率資料的方式。您可以直接用`wordcloud2`來製作文字雲。
為了讓文字雲看起來美觀些，請直接去掉最高頻的詞（通常都是「的」），讓文字雲中的詞頻比較均勻一點。

![](wordcloud_ref.png)

```{r president.bigram.wordcloud, echo=TRUE}
# your code goes here.
```

